"""
Helper class that maintains the cache evaluator mode information.
Manages the cache evaluator-specific data, the common data is
managed by the base class.

The object is set up to use the Python "with" syntax as follows:

    from maya.plugin.evaluator.CacheEvaluatorManager import CacheEvaluatorManager
    with CacheEvaluatorManager() as mgr:
        mgr.cache_mode = some_mode

That will ensure the original states are all restored. There's no other
reliable way to do it in Python. If you need different syntax you can
manually call the method to complete the sequence:

    mgr = CacheEvaluatorManager()
    mgr.save_state()
    mgr.cache_mode = some_mode
    mgr.restore_state()

If you attempt to read or write a state value and the plug-in is not loaded
then a ValueError will be raised with a plug-in not loaded message.
"""
import maya
maya.utils.loadStringResourcesForModule(__name__)

import maya.cmds as cmds
from maya.debug.TODO import TODO
from maya.debug.EvaluatorManager import EvaluatorManager
from maya.debug.PlaybackManager import PlaybackManager
from maya.app.prefs.OptionVar import OptionVar
from maya.plugin.evaluator.cache_optionvar_states import CachePreferenceHud, CachePreferenceResourceGuard, CachePreferenceMemoryThreshold, CachePreferenceDiscardFramesOutOfRange
import json
import warnings
from traceback import format_list, extract_tb

__all__ = [ 'CacheEvaluatorManager'
          , 'supported_shape_types_filter'
          , 'standard_modes'
          , 'CACHE_STANDARD_MODE_VP2_HW'
          , 'CACHE_STANDARD_MODE_VP2_SW'
          , 'CACHE_STANDARD_MODE_EVAL'
          , 'CACHE_STANDARD_MODE_EVAL_SHAPES'
          , 'CACHE_STANDARD_MODE_VP2_HW_NO_FALLBACK'
          , 'CACHE_STANDARD_MODE_VP2_SW_NO_FALLBACK'
          , 'KEY_CACHE_MODE'
          , 'KEY_ASYNCHRONOUS'
          , 'KEY_SAFE_MODE'
          , 'KEY_RESOURCE_GUARD'
          , 'KEY_MEMORY_THRESHOLD'
          , 'KEY_PREVENT_FRAME_SKIPPING'
          , 'KEY_DISCARD_FRAMES_OUT_OF_RANGE'
          , 'CACHE_PLUGIN_NAME'
          ]

# Name of the plug-in containing the cache evaluator
CACHE_PLUGIN_NAME = 'cacheEvaluator'

# Name of the evaluator
EVALUATOR_NAME = 'cache'

# Keys for the dictionary containing configuration information
KEY_CACHE_MODE                  = 'cache_mode'
KEY_ASYNCHRONOUS                = 'asynchronous'
KEY_FILL_MODE                   = 'fill_mode'
KEY_FILL_ORDER                  = 'fill_order'
KEY_HUD                         = 'hud'
KEY_FLUSH_SYNC                  = 'flush_sync'
KEY_SAFE_MODE                   = 'safe_mode'
KEY_RESOURCE_GUARD              = 'resource_guard'
KEY_MEMORY_THRESHOLD            = 'memory_threshold'
KEY_PREVENT_FRAME_SKIPPING      = 'prevent_frame_skipping'
KEY_DISCARD_FRAMES_OUT_OF_RANGE = 'discard_frames_out_of_range'

#======================================================================
def supported_shape_types_filter():
    ''':return: List of node types supporting caching'''
    return '+mesh,+nurbsCurve,+bezierCurve,+nurbsSurface,+subdiv,+lattice,+baseLattice,+cMuscleDebug,+cMuscleDirection,+cMuscleDisplace,+cMuscleDisplay,+cMuscleFalloff,+cMuscleKeepOut,+cMuscleObject,+cMuscleSmartCollide,+cMuscleSpline,+cMuscleSurfAttach,-THlocatorShape,+locator,+light,+camera,+imagePlane,+clusterHandle,+deformFunc,+hwShader,+pfxGeometry,+follicle'

#======================================================================

#
# Default modes
#

# VP2 Hardware Cache
CACHE_STANDARD_MODE_VP2_HW = [ { 'newFilter'      : 'evaluationCacheNodes'
                               , 'newAction'      : 'enableEvaluationCache' }
                             , { 'newFilter'      : 'vp2CacheNodes'
                               , 'newAction'      : 'enableVP2Cache'
                               , 'newActionParam' : 'useHardware=1' }
                             , { 'newRule'        : 'customEvaluators' } ]
# VP2 Software Cache
CACHE_STANDARD_MODE_VP2_SW = [ { 'newFilter'      : 'evaluationCacheNodes'
                               , 'newAction'      : 'enableEvaluationCache' }
                             , { 'newFilter'      : 'vp2CacheNodes'
                               , 'newAction'      : 'enableVP2Cache'
                               , 'newActionParam' : 'useHardware=0' }
                             , { 'newRule'        : 'customEvaluators' } ]
# Evaluation Cache
CACHE_STANDARD_MODE_EVAL = [ { 'newFilter' : 'evaluationCacheNodes'
                             , 'newAction' : 'enableEvaluationCache' }
                           , { 'newRule'   : 'customEvaluators' } ]

#
# Debugging modes
#

# Evaluation Cache for shapes only, no transform except the ones directly parenting shapes.
CACHE_STANDARD_MODE_EVAL_SHAPES = [ { 'newFilter'      : 'nodeTypes'
                                    , 'newFilterParam' : 'types=' + supported_shape_types_filter()
                                    , 'newAction'      : 'enableEvaluationCache' }
                                  , { 'newFilter'      : 'downstreamNodeTypes'
                                    , 'newFilterParam' : 'types=+dagNode downstreamTypes=' + supported_shape_types_filter()
                                    , 'newAction'      : 'enableEvaluationCache' }
                                  , { 'newRule'        : 'customEvaluators' } ]
# VP2 Hardware Cache (Without Fallback)
CACHE_STANDARD_MODE_VP2_HW_NO_FALLBACK = [ { 'newFilter'      : 'evaluationCacheNodes'
                                           , 'newAction'      : 'enableEvaluationCache' }
                                         , { 'newFilter'      : 'vp2CacheNodes'
                                           , 'newAction'      : 'enableVP2Cache'
                                           , 'newActionParam' : 'useHardware=1 fallback=0' }
                                         , { 'newRule'        : 'customEvaluators' } ]
# VP2 Software Cache (Without Fallback)
CACHE_STANDARD_MODE_VP2_SW_NO_FALLBACK = [ { 'newFilter'      : 'evaluationCacheNodes'
                                           , 'newAction'      : 'enableEvaluationCache' }
                                         , { 'newFilter'      : 'vp2CacheNodes'
                                           , 'newAction'      : 'enableVP2Cache'
                                           , 'newActionParam' : 'useHardware=0 fallback=0' }
                                         , { 'newRule'        : 'customEvaluators' } ]

#======================================================================
def standard_modes():
    ''':return: List of (name,parameter_list) state setup values for the current standard set of usable modes'''
    return [
        ('VP2_HW', CACHE_STANDARD_MODE_VP2_HW)
    ,   ('VP2_SW', CACHE_STANDARD_MODE_VP2_SW)
    ,   ('EVAL', CACHE_STANDARD_MODE_EVAL)
    ,   ('EVAL_SHAPES', CACHE_STANDARD_MODE_EVAL_SHAPES)
        ]

#======================================================================
def non_vp2_viewport_exists():
    '''
    Return True if a viewport that does not use Viewport 2.0 exists.
    '''
    panels = cmds.getPanel(visiblePanels=True)
    if panels is None:
        return False

    modelEditors = [panel for panel in panels if cmds.modelEditor(panel, query=True, exists=True)]
    for panel in modelEditors:
        rendererName = cmds.modelEditor(panel, query=True, rendererName=True)
        if not rendererName == 'vp2Renderer':
            return True
    return False

#======================================================================
class CacheEvaluatorManager(EvaluatorManager):
    '''
    Class for managing the cache evaluator state in a 'with' format. Remembers
    and restores the caching mode and parameters.
    '''
    #----------------------------------------------------------------------
    class CacheEvaluatorState(EvaluatorManager.EvaluatorState):
        '''
        State information of the evaluator
            :member fill_mode:                   When to fill the cache
            :member fill_order:                  The order for background cache filling
            :member hud:                         Whether or not the caching information is displayed in the heads-up display
            :member flush_sync:                  Use synchronous flush if true or asynchronus flush if false
            :member cache_mode:                  Array of rules description for the current mode
            :member safe_mode:                   Is the cache evaluation currently in safe mode?
            :member resource_guard:              Is the memory resource safeguard enabled?
            :member memory_threshold:            Maximum percentage of memory to occupy before shutting down caching
            :member prevent_frame_skipping:      Should frames be skipped when filling in frame-rate locked modes?
            :member discard_frames_out_of_range: Should cached frames be released when they are not in playback range
        '''
        def __init__(self):
            '''Set the state information to some default values'''
            super( CacheEvaluatorManager.CacheEvaluatorState, self ).__init__()
            self.fill_mode                   = None
            self.fill_order                  = None
            self.hud                         = None
            self.flush_sync                  = None
            self.cache_mode                  = None
            self.safe_mode                   = None
            self.resource_guard              = None
            self.memory_threshold            = None
            self.prevent_frame_skipping      = None
            self.discard_frames_out_of_range = None

    #----------------------------------------------------------------------
    def save_state(self):
        '''
        Remember the current state of all EM related parameters so that they
        can be restored on exit.
        '''
        self.dbg( 'CacheEvaluatorManager.save_state' )
        self.state = CacheEvaluatorManager.CacheEvaluatorState()
        super( CacheEvaluatorManager, self ).save_state()

        # These values will be remembered even if the plug-in is not loaded because they
        # are stored as optionVars.
        self.state.resource_guard = self.resource_guard
        self.state.memory_threshold = self.memory_threshold

        TODO( 'Finish', 'If the plug-in is not loaded some state information is still available directly from the OptionVars, but including them would create a circular inclusion here', None )
        # If the plug-in is not loaded there's no data to collect
        if not self.state.plugin_loaded:
            return

        #----------------------------------------
        # Cache-specific parameters
        self.state.cache_mode                  = self.cache_mode
        self.state.fill_mode                   = self.fill_mode
        self.state.fill_order                  = self.fill_order
        self.state.hud                         = self.hud
        self.state.flush_sync                  = self.flush_sync
        self.state.safe_mode                   = self.safe_mode
        self.state.resource_guard              = self.resource_guard
        self.state.memory_threshold            = self.memory_threshold
        self.state.prevent_frame_skipping      = self.prevent_frame_skipping
        self.state.discard_frames_out_of_range = self.discard_frames_out_of_range

    #----------------------------------------------------------------------
    def __init__(self):
        '''
        __enter__ is defined in the parent class
        '''
        self.state = None
        super( CacheEvaluatorManager, self ).__init__( EVALUATOR_NAME, CACHE_PLUGIN_NAME )

        self.dbg( 'CacheEvaluatorManager.__init__' )
        # This may not be used but it will be available for reference
        self.save_state()

    #----------------------------------------------------------------------
    def __exit__(self,event_type,value,traceback): # pylint: disable=redefined-builtin
        '''Ensure the state is restored if this object goes out of scope'''

        self.dbg( 'CacheEvaluatorManager.__exit__' )
        self.dbg( '    Event Type = {}'.format(event_type) )
        self.dbg( '    Value      = {}'.format(value) )
        self.dbg( '    Traceback  = {}'.format('\n              > '.join(format_list(extract_tb(traceback)))) )

        self.restore_state()

    #----------------------------------------------------------------------
    def check_plugin(self):
        '''
        Confirm that the plug-in is loaded.
        :raise OptionVar.StateError: The plug-in is not currently loaded
        '''
        if not self.plugin_loaded:
            raise OptionVar.StateError( maya.stringTable['y_CacheEvaluatorManager.kPluginNotLoaded' ].format( EVALUATOR_NAME ) )

    #----------------------------------------------------------------------
    @staticmethod
    def flush_cache():
        '''Flush the current cache, if any'''
        try:
            cmds.cacheEvaluator(flushCache='destroy')
        except RuntimeError:
            # Cache evaluator is not available so nothing to do
            pass

    #----------------------------------------------------------------------
    @staticmethod
    def flush_cache_range(min_time, max_time, flush_inside_range):
        '''
        Flush a portion of the current cache, if any
        :param min_time: Start of the time range for flushing
        :param max_time: End of the time range for flushing
        :param flush_inside_range: If True then flush anything in [min_time,max_time],
            otherwise flush anything outside that range (i.e. [-inf,min_time) U (max_time, inf])
        '''
        try:
            cmds.cacheEvaluator(flushCacheRange=[(min_time, max_time), flush_inside_range])
        except RuntimeError:
            # Cache evaluator is not available so nothing to do
            pass

    #----------------------------------------------------------------------
    @staticmethod
    def wait_for_cache(max_time=2.0):
        '''
        Wait for any pending cache fills.
        :param max_time: Maximum number of seconds to wait for the cache to fill (0 = just check without waiting)
        :return: True if the cache is ready after waiting
        '''
        cache_is_ready = False
        try:
            cmds.flushIdleQueue()   # In case a background evaluation has been queued up but not started
            cache_is_ready = cmds.cacheEvaluator(waitForCache=max_time)
        except RuntimeError:
            # Cache evaluator is not available so nothing to do
            cache_is_ready = True
        return cache_is_ready

    #----------------------------------------------------------------------
    @staticmethod
    def invalidate_cache():
        '''Invalidate the current cache, if any'''
        try:
            with PlaybackManager() as play_mgr:
                cmds.cacheEvaluator( cacheInvalidate=('{0}'.format(play_mgr.minTime), '{0}'.format(play_mgr.maxTime)) )
        except RuntimeError:
            # Cache evaluator is not available so nothing to do
            pass

    #----------------------------------------------------------------------
    def rebuild_cache(self, wait_for_rebuild):
        '''
        Rebuild the current cache, if available
        :param wait_for_rebuild: If true then do not return until the cache has rebuilt
        :return: True if the cache was rebuilt and is available
        '''
        cache_available = False
        try:
            if not self.enabled:
                cmds.warning( maya.stringTable['y_CacheEvaluatorManager.kNoRebuildWhenDisabled'  ] )
            elif self.safe_mode_triggered:
                cmds.warning( maya.stringTable['y_CacheEvaluatorManager.kNoRebuildInSafeMode'  ] )
            else:
                # If in safe mode or rebuilding synchronously a playback has to run to rebuild
                # the cache, otherwise just a time setting is needed and optional wait
                if self.fill_mode != 'syncOnly':
                    cmds.currentTime( cmds.currentTime(query=True) )
                    wait_time = 999 if wait_for_rebuild else 0
                    cache_available = cmds.cacheEvaluator( waitForCache=wait_time )
                elif not wait_for_rebuild:
                    cmds.warning( maya.stringTable['y_CacheEvaluatorManager.kHaveToWaitInSyncMode'  ] )
                else:
                    play_mgr = PlaybackManager()
                    play_mgr.play_all()
                    cache_available = cmds.cacheEvaluator( waitForCache=0 )
        except RuntimeError:
            # Cache evaluator is not available so nothing to do
            pass

        return cache_available

    #----------------------------------------------------------------------
    def cached_nodes(self, potential_nodes):
        '''
        Find the currently cached nodes. This method doesn't care which cache the values are in
        only that at least one cache has data for a given node.
        :param potential_nodes: Set of nodes to check for caching. If None then use the list of
                                all evaluation graph nodes instead.
        :return: Set of nodes with data in a cache
        '''
        cached_nodes = set()
        try:
            caching_points = cmds.cacheEvaluator( query=True, cachingPoints=True )
            cached_nodes = set(caching_points) & (potential_nodes or set())

        except (ValueError, KeyError), ex:
            # Extraction may have failed when the graph doesn't exist or when the evaluator
            # command failed.
            self.dbg( 'Failed to extract the list of cached nodes ({})'.format(ex) )

        return cached_nodes

    #----------------------------------------------------------------------
    def as_json(self):
        '''Display mechanism to retrieve evaluator information in a format conducive to JSON formatting'''

        info = super( CacheEvaluatorManager, self ).as_json()

        if not self.plugin_loaded:
            return

        info.update( { KEY_CACHE_MODE                  : self.cache_mode
                     , KEY_FILL_MODE                   : self.fill_mode
                     , KEY_FILL_ORDER                  : self.fill_order
                     , KEY_HUD                         : self.hud
                     , KEY_FLUSH_SYNC                  : self.flush_sync
                     , KEY_SAFE_MODE                   : self.safe_mode
                     , KEY_RESOURCE_GUARD              : self.resource_guard
                     , KEY_MEMORY_THRESHOLD            : self.memory_threshold
                     , KEY_PREVENT_FRAME_SKIPPING      : self.prevent_frame_skipping
                     , KEY_DISCARD_FRAMES_OUT_OF_RANGE : self.discard_frames_out_of_range
                     } )

        return info

    #----------------------------------------------------------------------
    def set_state(self, new_state):
        '''
        Define the cache evaluator state parameters.
        :param new_state: State information in the format provided by as_json
                          Only key values specified will change. Others retain
                          their current values (*not* default values).
        '''
        if not self.plugin_loaded:
            return

        super( CacheEvaluatorManager, self ).set_state( new_state )

        self.dbg( 'CacheEvaluatorManager.set_state to {}'.format( new_state ) )

        for key,value in new_state.iteritems():
            if key == KEY_CACHE_MODE:
                self.cache_mode = value
            elif key == KEY_ASYNCHRONOUS:
                self.asynchronous = value
            elif key == KEY_FILL_MODE:
                self.fill_mode = value
            elif key == KEY_FILL_ORDER:
                self.fill_order = value
            elif key == KEY_HUD:
                self.hud = value
            elif key == KEY_FLUSH_SYNC:
                self.flush_sync = value
            elif key == KEY_SAFE_MODE:
                self.safe_mode = value
            elif key == KEY_RESOURCE_GUARD:
                self.resource_guard = value
            elif key == KEY_MEMORY_THRESHOLD:
                self.memory_threshold = value
            elif key == KEY_PREVENT_FRAME_SKIPPING:
                self.prevent_frame_skipping = value
            elif key == KEY_DISCARD_FRAMES_OUT_OF_RANGE:
                self.discard_frames_out_of_range = value
            # No else case because the base class has its own keys

    #----------------------------------------------------------------------
    def restore_state(self):
        '''
        Restore the cache evaluator to its original mode prior to creation of
        this object. Using the "with" syntax this will be called automatically.
        You only need to call explicitly when you instantiate the mode manager
        as an object.
        '''
        self.dbg( 'CacheEvaluatorManager.restore_state' )

        super( CacheEvaluatorManager, self ).restore_state()

        # Restore the evaluator state. If the state wasn't taken from a loaded plug-in then it
        # wasn't valid.
        if self.state.plugin_loaded:
            self.plugin_loaded = True # Force loading the plug-in so that state can be restored
            self.cache_mode                  = self.state.cache_mode
            self.fill_mode                   = self.state.fill_mode
            self.fill_order                  = self.state.fill_order
            self.hud                         = self.state.hud
            self.flush_sync                  = self.state.flush_sync
            self.safe_mode                   = self.state.safe_mode
            self.resource_guard              = self.state.resource_guard
            self.memory_threshold            = self.state.memory_threshold
            self.prevent_frame_skipping      = self.state.prevent_frame_skipping
            self.discard_frames_out_of_range = self.state.discard_frames_out_of_range

        # These are optionVars and do not rely on the plug-in
        self.resource_guard = self.state.resource_guard
        self.memory_threshold = self.state.memory_threshold

        # Load or unload the plug-in, as it was when state was saved
        self.plugin_loaded = self.state.plugin_loaded

    #----------------------------------------------------------------------
    #
    # Use properties to make it easier to access the evaluator information
    #
    @property
    def fill_mode(self):
        ''' :return: the evaluator's current fill mode, decide when the cache will be filled.  '''
        self.check_plugin()
        return cmds.cacheEvaluator(query=True, cacheFillMode=True)

    @fill_mode.setter
    def fill_mode(self, new_value):
        '''
        Give the evaluator a new fill mode
        :param new_value: new value for fill mode, must be one of ['asyncOnly', 'syncOnly', 'syncAsync']
        '''
        self.check_plugin()
        self.dbg( 'Setting fill mode to {}'.format(new_value) )
        try:
            cmds.cacheEvaluator(cacheFillMode = new_value)
        except Exception, ex:
            self.err( '--- Failed : {}'.format(ex) )

    #----------------------------------------------------------------------
    @property
    def asynchronous(self):
        '''
        :return: the evaluator's asynchronous state.
        The conversions are needed because the command returns the true/false value as a string.
        '''
        warnings.warn(
            "asynchronous is deprecated, use fill_mode instead",
            DeprecationWarning
        )
        mode = self.fill_mode
        return mode == 'asyncOnly' or mode == 'syncAsync'

    @asynchronous.setter
    def asynchronous(self, new_value):
        '''
        Give the evaluator a new asynchronous state
        :param new_value: New asynchronous state for the evaluator
        '''
        warnings.warn(
            "asynchronous is deprecated, use fill_mode instead",
            DeprecationWarning
        )
        if new_value:
            mode = 'syncAsync'
        else:
            mode = 'syncOnly'
        self.fill_mode = mode

    #----------------------------------------------------------------------
    @property
    def fill_order(self):
        ''' :return: the evaluator's background fill order '''
        self.check_plugin()
        return cmds.cacheEvaluator(query=True, cacheFillOrder=True)

    @fill_order.setter
    def fill_order(self, new_value):
        '''
        Give the evaluator a new background fill order
        :param new_value: new value for fill order, must be one of ['forward', 'backward', 'bidirectional', 'forwardFromBegin']
        '''
        self.check_plugin()
        self.dbg( 'Setting fill order to {}'.format(new_value) )
        try:
            cmds.cacheEvaluator( cacheFillOrder = new_value )
        except Exception, ex:
            self.err( '--- Failed : {}'.format(ex) )

    #----------------------------------------------------------------------
    @property
    def flush_sync(self):
        ''' :return: the evaluator's flush synchronization mode '''
        self.check_plugin()
        return bool(int(cmds.cacheEvaluator(query=True, flushCacheSync=True)))

    @flush_sync.setter
    def flush_sync(self, new_value):
        '''
        Give the evaluator a new flush synchronization mode
        :param new_value: new value for fill order, True for synchronous flush, False for asynchronous flush
        '''
        if bool(int(new_value)):
            self.dbg( 'Setting flush sync mode to synchronous' )
        else:
            self.dbg( 'Setting flush sync mode to asynchronous' )

        try:
            cmds.cacheEvaluator( flushCacheSync = bool(int(new_value)) )
        except Exception, ex:
            self.err( '--- Failed : {}'.format(ex) )

    #----------------------------------------
    @property
    def cache_mode(self):
        ''':return: the list of rules descriptions being used for the current caching mode'''
        self.check_plugin()
        try:
            caching_mode = json.loads( cmds.cacheEvaluator( query=True, creationParameters=True ) )
        except RuntimeError:
            caching_mode = []
        # json.loads creates unicode strings as keys which cannot be used as argument names when
        # unpacking the dictionary, which prevents doing something like cmds.cacheEvaluator(**rule)
        # so we convert them to ascii.
        return [{key.encode('ascii'): value for key, value in rule.iteritems()} for rule in caching_mode]

    @cache_mode.setter
    def cache_mode(self, new_value):
        '''
        Give the evaluator a new set of cache configuration rules to use as the current mode
        :param new_value: List of rules descriptions to use for caching mode
        '''
        self.check_plugin()
        current_values = self.cache_mode
        if current_values == new_value:
            return

        self.dbg( 'Setting cache mode to {}'.format(new_value) )
        try:
            cmds.cacheEvaluator( resetRules=True )
            for rule in new_value:
                cmds.cacheEvaluator( **rule )

            # Need a warning if the caching mode was set to a VP2 mode but one or more viewports
            # do not use the VP2 renderer.
            vp2_caching = (new_value == CACHE_STANDARD_MODE_VP2_SW or new_value == CACHE_STANDARD_MODE_VP2_HW)
            if vp2_caching and non_vp2_viewport_exists():
                cmds.warning(maya.stringTable['y_CacheEvaluatorManager.kNonVP2UsedInVP2Caching' ])

        except Exception, ex:
            self.err( '--- Failed : {}'.format(ex) )

    #----------------------------------------
    @property
    def prevent_frame_skipping(self):
        ''':return: the evaluator's prevent-frame-skipping state value'''
        self.check_plugin()
        return True if int(cmds.cacheEvaluator(query=True, preventFrameSkip=True)) else False

    @prevent_frame_skipping.setter
    def prevent_frame_skipping(self, new_value):
        '''
        Set the prevent-frame-skipping state for the evaluator.
        :param new_value: New prevent-frame-skipping state for the evaluator
        '''
        self.check_plugin()
        if self.prevent_frame_skipping == new_value:
            return

        self.dbg( 'Setting prevent-frame-skipping state to {}'.format(new_value) )
        try:
            cmds.cacheEvaluator(preventFrameSkip=new_value)
        except Exception, ex:
            self.err( '--- Failed : {}'.format(ex) )

    #----------------------------------------
    @property
    def resource_state(self):
        '''
        :return: String representing current resource usage compared to the limits
            unlimited   Usage is not being checked
            out         No Memory Left - 100% hit
            low         Between 90% and 100% usage
            okay        Less than 90% usage
        '''
        self.check_plugin()
        return cmds.cacheEvaluator( resourceUsage=True, query=True )

    #----------------------------------------
    @property
    def safe_mode_triggered(self):
        ''':return: the evaluator's safe mode triggered value (a read-only value)'''
        self.check_plugin()
        return bool(int(cmds.cacheEvaluator( safeModeTriggered=True, query=True )))

    #----------------------------------------------------------------------
    @property
    def safe_mode_messages(self):
        ''':return: The messages, if safe mode was triggered. Otherwise returns None. (a read-only value)'''
        self.check_plugin()
        if self.safe_mode_triggered:
            return cmds.cacheEvaluator(query=True, safeModeMessages=True)

        return None

    #----------------------------------------
    @property
    def safe_mode(self):
        ''':return: the evaluator's safe mode value'''
        self.check_plugin()
        return bool(int(cmds.cacheEvaluator( safeMode=True, query=True )))

    @safe_mode.setter
    def safe_mode(self, new_value):
        '''
        Give the evaluator a new safe mode state
        :param new_value: New safe mode state for the evaluator
        '''
        self.check_plugin()
        if self.safe_mode == new_value:
            return

        self.dbg( 'Setting safe mode to {}'.format(new_value) )
        try:
            cmds.cacheEvaluator( safeMode=new_value )
        except Exception, ex:
            self.err( '--- Failed : {}'.format(ex) )

    #----------------------------------------
    @property
    def hud(self):
        ''':return: the evaluator's HUD display state value'''
        assert self is not None
        return cmds.optionVar(query=CachePreferenceHud().ov_id)

    @hud.setter
    def hud(self, new_value):
        '''
        Set the HUD display state for the evaluator. (Actually it's an optionVar but it only
        applies to this evaluator so the effect is the same.)
        :param new_value: New HUD display state for the evaluator
        '''
        if self.hud == new_value:
            return

        self.dbg( 'Setting caching HUD display state to {}'.format(new_value) )
        try:
            cmds.optionVar( intValue=(CachePreferenceHud().ov_id,new_value) )
        except Exception, ex:
            self.err( '--- Failed : {}'.format(ex) )

    #----------------------------------------
    @property
    def resource_guard(self):
        ''':return: the evaluator's resource guard state value'''
        assert self is not None
        return cmds.optionVar(query=CachePreferenceResourceGuard().ov_id)

    @resource_guard.setter
    def resource_guard(self, new_value):
        '''
        Set the resource guard state for the evaluator. (Actually it's an optionVar but it only
        applies to this evaluator so the effect is the same.)
        :param new_value: New resource guard state for the evaluator
        '''
        if self.resource_guard == new_value:
            return

        self.dbg( 'Setting resource guard state to {}'.format(new_value) )
        try:
            cmds.optionVar( intValue=(CachePreferenceResourceGuard().ov_id,new_value) )
        except Exception, ex:
            self.err( '--- Failed : {}'.format(ex) )

    #----------------------------------------
    @property
    def memory_threshold(self):
        ''':return: the evaluator's resource guard state value'''
        assert self is not None
        return cmds.optionVar(query=CachePreferenceMemoryThreshold().ov_id)

    @memory_threshold.setter
    def memory_threshold(self, new_value):
        '''
        Set the memory threshold for the evaluator. (Actually it's an optionVar but it only
        applies to this evaluator so the effect is the same.)
        :param new_value: New memory threshold for the evaluator
        '''
        if self.memory_threshold == new_value:
            return

        self.dbg( 'Setting memory threshold to {}'.format(new_value) )
        try:
            cmds.optionVar( floatValue=(CachePreferenceMemoryThreshold().ov_id,new_value) )
        except Exception, ex:
            self.err( '--- Failed : {}'.format(ex) )

    #----------------------------------------
    @property
    def discard_frames_out_of_range(self):
        ''':return: the evaluator's state value for discarding cache data outside the playback range'''
        assert self is not None
        return cmds.optionVar(query=CachePreferenceDiscardFramesOutOfRange().ov_id)

    @discard_frames_out_of_range.setter
    def discard_frames_out_of_range(self, new_value):
        '''
        Set the state for discarding cache data outside of the playback range for the evaluator.
        (Actually it's an optionVar but it only applies to this evaluator so the effect is the same.)
        :param new_value: New discard state for the evaluator
        '''
        if self.discard_frames_out_of_range == new_value:
            return

        self.dbg( 'Setting out of range frame discard control to {}'.format(new_value) )
        try:
            cmds.optionVar( intValue=(CachePreferenceDiscardFramesOutOfRange().ov_id,new_value) )
        except Exception, ex:
            self.err( '--- Failed : {}'.format(ex) )

# ===========================================================================
# Copyright 2018 Autodesk, Inc. All rights reserved.
#
# Use of this software is subject to the terms of the Autodesk license
# agreement provided at the time of installation or download, or which
# otherwise accompanies this software in either electronic or hard copy form.
# ===========================================================================
