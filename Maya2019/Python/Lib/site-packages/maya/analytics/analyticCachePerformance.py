"""
Run a set of performance tests on caching modes.

See the class docs for a description of the data collected.

"""
import maya
maya.utils.loadStringResourcesForModule(__name__)

import json
import maya.cmds as cmds
from .BaseAnalytic import BaseAnalytic, OPTION_DETAILS
from .decorators import addMethodDocs,addHelp,makeAnalytic
from maya.debug.emModeManager import emModeManager
from maya.debug.PlaybackManager import PlaybackManager
from maya.debug.EvaluatorManager import KEY_ENABLED, KEY_LOADED
from maya.plugin.evaluator.CacheEvaluatorManager import CacheEvaluatorManager, KEY_CACHE_MODE #, KEY_RESOURCE_LIMIT, KEY_RESOURCE_GUARD, KEY_MEMORY_THRESHOLD
from maya.plugin.evaluator.CacheEvaluatorManager import CACHE_STANDARD_MODE_VP2_HW, CACHE_STANDARD_MODE_VP2_SW, CACHE_STANDARD_MODE_EVAL, CACHE_STANDARD_MODE_EVAL_SHAPES

# Maximum number of frames for playback timing
MAX_FRAMES = 20

# Special time value indicating that the cache was unavailable, and therefore could not be measured
CACHE_UNAVAILABLE = -1.0

# Unlikely to change but might as well make this common
EVALUATOR_NAME = 'cache'

# Keywords used in the output dictionaries
KEY_BASELINE    = 'baseline'
KEY_MEMORY      = 'memory'
KEY_PLAYBACK    = 'playback'
KEY_START_FRAME = 'start_frame'
KEY_END_FRAME   = 'end_frame'
#
KEY_CACHING            = 'caching'
KEY_CONFIGURATION      = 'configuration'
KEY_CONFIGURATION_NAME = 'configuration_name'
KEY_CACHING_POINTS     = 'caching_points'
KEY_FRAMES_CACHED      = 'frames_cached'
KEY_CACHED_DATA        = 'cached_data'
KEY_NODE_COUNT         = 'count'
KEY_NODE_MEMORY        = 'memory'
KEY_FILLING_PLAYBACK   = 'filling_playback'
KEY_CACHED_PLAYBACK    = 'cached_playback'
KEY_FILL_TIME          = 'fill_time'
KEY_MEMORY_BEFORE      = 'memory_before_playback'
KEY_MEMORY_AFTER       = 'memory_after_playback'
KEY_EVACUATION         = 'evacuation_time'

@addMethodDocs
@addHelp
@makeAnalytic(False)
class analyticCachePerformance(BaseAnalytic):
    """
    The normal output is the set of cache performance statistics.

        {
          "baseline"    : {
              "memory"      : [0,0]  // baseline [physical,virtual] memory usage after animation, but before caching
            , "playback"    : 0      // frames-per-second for non-caching EMP playback
            , "start_frame" : 0
            , "end_frame"   : 0      // start and end frames being used for the test
            }
        // for each of the cache testing modes
        , "caching" : [
            { "configuration_name" : "XXX"     // the name given to this configuration for identification purposes
            , "configuration"      : { ... }   // the configuration information for the cache evaluator
            , "caching_points"     : { ... }   // caching points used by the cache evaluator for this run
            , "frames_cached"      : [[S1,E1],
                                      [S2,E2]] // list of frame ranges cached
            , "cached_data"        : {         // counts and memory used for each node type enabled as a caching point
               "NODE_TYPE" : {
                 "count"  : 0,
                 "memory" : 0} }
            , "filling_playback"       : 0       // frames-per-second for playback while the cache is refilling synchronously
            , "fill_time"              : 0       // amount of time it took to fill the cache in the background, in seconds
                                                 //    (while nothing is going on in the foreground)
            , "cached_playback"        : 0       // frames-per-second for playback from cached data
            , "memory_before_playback" : [0,0]   // overall Maya [physical,virtual] memory usage after caching
            , "memory_after_playback"  : [0,0]   // overall Maya [physical,virtual] memory usage after caching playback
            , "evacuation_time"        : 0       // amount of time it takes to evacuate the cache, in seconds
            }
          ]
        }

    Several values in this output are lists. If the 'details' option is specified then the full
    list is included in the output. Otherwise the list is replaced by a count of the list members.
    These members include:
        OUT[KEY_CACHING][KEY_CACHING_POINTS]
        OUT[KEY_CACHING][KEY_CONFIGURATION][KEY_CACHE_MODE]
    """
    ANALYTIC_LABEL = maya.stringTable['y_analyticCachePerformance.kAnalyticLabel' ]
    ANALYTIC_DESCRIPTION_SHORT = maya.stringTable['y_analyticCachePerformance.kAnalyticDescriptionShort' ]

    def __init__(self):
        """
        Initialize the persistent class members
        """
        super(self.__class__, self).__init__()

        # List of configurations to test, formatted as required by the CacheEvaluatorManager's
        # set_state method (key:value pairs with configuration information).
        #
        # This is the default list, though it can be overridden be anyone calling it so long as
        # it is done before run() is called.
        #
        self.configurations_to_run = [
                {
                    'name' : 'Evaluation',
                    KEY_CONFIGURATION : {
                            KEY_CACHE_MODE       : CACHE_STANDARD_MODE_EVAL
                          #, KEY_RESOURCE_LIMIT   :
                          #, KEY_RESOURCE_GUARD   :
                          #, KEY_MEMORY_THRESHOLD :
                          , KEY_ENABLED          : True
                          , KEY_LOADED           : True
                          #, KEY_CONSOLIDATION    :
                    }
                },
                {
                    'name' : 'VP2 Software',
                    KEY_CONFIGURATION : {
                            KEY_CACHE_MODE       : CACHE_STANDARD_MODE_VP2_SW
                          #, KEY_RESOURCE_LIMIT   :
                          #, KEY_RESOURCE_GUARD   :
                          #, KEY_MEMORY_THRESHOLD :
                          , KEY_ENABLED          : True
                          , KEY_LOADED           : True
                          #, KEY_CONSOLIDATION    :
                    }
                },
                {
                    'name' : 'VP2 Hardware',
                    KEY_CONFIGURATION : {
                            KEY_CACHE_MODE       : CACHE_STANDARD_MODE_VP2_HW
                          #, KEY_RESOURCE_LIMIT   :
                          #, KEY_RESOURCE_GUARD   :
                          #, KEY_MEMORY_THRESHOLD :
                          , KEY_ENABLED          : True
                          , KEY_LOADED           : True
                          #, KEY_CONSOLIDATION    :
                    }
                }
            ]


    #----------------------------------------------------------------------
    def get_memory(self):
        '''
        :return: A 2 member list with current physical and virtual memory in use by Maya
        '''
        return [ cmds.memory(asFloat=True, megaByte=True, physicalMemory=True)
               , cmds.memory(asFloat=True, megaByte=True, adjustedVirtualMemory=True) ]

    #----------------------------------------------------------------------
    def run(self):
        """
        Run the analytic on the current scene.
        Performs a playback for a set of caching modes, recording the memory usage
        and timing for each of them along with the default configuration for reference.
        :result: JSON data as described in the class doc
        """
        json_data = { KEY_BASELINE : { KEY_MEMORY      : [0,0]
                                     , KEY_PLAYBACK    : 0
                                     , KEY_START_FRAME : 0
                                     , KEY_END_FRAME   : 0
                                     }
                    , KEY_CACHING  : []
                    }
        caching_template = { KEY_CONFIGURATION_NAME : ""
                           , KEY_CONFIGURATION      : []
                           , KEY_FRAMES_CACHED      : []
                           , KEY_CACHING_POINTS     : {}
                           , KEY_CACHED_DATA        : {}
                           , KEY_FILLING_PLAYBACK   : 0
                           , KEY_CACHED_PLAYBACK    : 0
                           , KEY_FILL_TIME          : 0
                           , KEY_MEMORY_BEFORE      : 0
                           , KEY_MEMORY_AFTER       : 0
                           , KEY_EVACUATION         : 0
                           }

        baseline_data = json_data[KEY_BASELINE]
        caching_data = json_data[KEY_CACHING]

        with emModeManager() as em_mgr, PlaybackManager() as play_mgr, CacheEvaluatorManager() as cache_mgr:

            if self.option(OPTION_DETAILS):
                em_mgr.debugging( True )
                play_mgr.debugging( True )
                cache_mgr.debugging( True )

            # Determine what frames are being used
            (min_time, max_time) = play_mgr.limited_range( MAX_FRAMES, from_start=True )
            baseline_data[KEY_START_FRAME] = min_time
            baseline_data[KEY_END_FRAME] = max_time
            assert max_time >= min_time
            playback_length = max_time - min_time + 1.0

            # Get the system into a stable state - default EM mode with caching off
            cache_mgr.enabled = False
            cache_mgr.flush_sync = True
            em_mgr.rebuild( include_scheduling=True )
            play_mgr.play_limited_range( 3, from_start=True )

            # Have to set the range specifically rather than playLimitedRange because the cache
            # evaluator uses the range to decide what to file.
            play_mgr.set_limited_range( MAX_FRAMES, from_start=True )

            # Run playback timing in regular mode
            (elapsed, played_frames) = play_mgr.play_for(5)
            baseline_data[KEY_PLAYBACK] = played_frames/elapsed if elapsed > 0.0 else 0.0
            self.debug( 'Finished baseline playback in {} at {}fps'.format( elapsed, baseline_data[KEY_PLAYBACK] ) )

            # Take baseline memory measurements after playback since we're only measuring cache usage
            baseline_data[KEY_MEMORY] = self.get_memory()

            # Loop through all of the different caching types
            for configuration_to_run in self.configurations_to_run:
                self.debug( 'Running caching configuration "{}"'.format( configuration_to_run['name'] ) )
                self.debug( 'Set state to "{}"'.format( configuration_to_run[KEY_CONFIGURATION] ) )

                # Setup the new configuration of the cache evaluator
                cache_mgr.set_state( configuration_to_run[KEY_CONFIGURATION] )

                caching_results = dict(caching_template)

                # configuration_to_run only has values being set so we have to retrieve
                # the full configuration for reporting purposes
                configuration = json.loads( str(cache_mgr) )

                self.debug( 'Logged state "{}"'.format( configuration ) )

                # When not in detailed mode only the cache configuration rules count is reported
                if not self.option(OPTION_DETAILS):
                    configuration['cache_mode'] =  len(configuration['cache_mode'])

                caching_results[KEY_CONFIGURATION] = configuration
                caching_results[KEY_CONFIGURATION_NAME] = configuration_to_run['name']

                # Memory before playback
                caching_results[KEY_MEMORY_BEFORE] = self.get_memory()

                # Cache fill time (background)
                self.debug( '--- Filling cache' )
                cache_mgr.asynchronous = 1
                cmds.cacheEvaluator( flushCache='destroy' ) # Just in case some cache data snuck in
                start_time = cmds.timerX()
                cmds.currentTime( cmds.currentTime(query=True) )
                cache_available = cmds.cacheEvaluator( waitForCache=999 )
                caching_results[KEY_FILL_TIME] = cmds.timerX( startTime=start_time )

                # Cached playback
                self.debug( '--- Running cached playback' )
                if cache_available:
                    (elapsed, played_frames) = play_mgr.play_for(5)
                    caching_results[KEY_CACHED_PLAYBACK] = played_frames/elapsed if elapsed > 0.0 else CACHE_UNAVAILABLE
                else:
                    # Unavailable cache means results can't be gathered.
                    caching_results[KEY_CACHED_PLAYBACK] = CACHE_UNAVAILABLE

                # Memory after playback
                caching_results[KEY_MEMORY_AFTER] = self.get_memory()

                # Contents of the cache
                # This is very specific to the info format so be careful with it
                self.debug( '--- Gathering cache content information' )
                try:
                    cache_info = cmds.evaluator( name=EVALUATOR_NAME, query=True, info=True ).splitlines()
                    frame_range = cache_info[0].rstrip().split(' ')[2:] # Cached Frames XX XX XX
                    caching_results[KEY_FRAMES_CACHED] = frame_range

                    caching_point_data = caching_results[KEY_CACHED_DATA]
                    # Cached node data - skip the title
                    for line in cache_info[2:]:
                        (node_type,node_count,node_memory) = line.rstrip().split(',')
                        caching_point_data[node_type] = { KEY_NODE_COUNT : int(node_count), KEY_NODE_MEMORY : float(node_memory) }

                    # Get the list of cached nodes
                    caching_results[KEY_CACHING_POINTS] = cmds.cacheEvaluator( query=True, listCachedNodes=True )
                except Exception, ex:
                    self.error( 'Could not parse cache info {}\n{}'.format(ex,'\n'.join(cache_info)) )

                # Evacuation time
                self.debug( '--- Evacuating the cache' )
                start_time = cmds.timerX()
                cmds.cacheEvaluator( flushCache='destroy' )
                caching_results[KEY_EVACUATION] = cmds.timerX( startTime=start_time )

                # Cache fill and playback time (foreground)
                self.debug( '--- Playing back while filling the cache' )
                cache_mgr.asynchronous = 0
                start_time = cmds.timerX()
                play_mgr.play_all()
                caching_results[KEY_FILLING_PLAYBACK] = playback_length/cmds.timerX( startTime=start_time )

                if not self.option(OPTION_DETAILS):
                    try:
                        caching_results[KEY_CACHING_POINTS] = len(caching_results[KEY_CACHING_POINTS])
                        caching_results[KEY_CACHED_DATA] = { 'Total' : caching_results[KEY_CACHED_DATA]['Total'] }
                    except KeyError:
                        caching_results[KEY_CACHED_DATA] = { 'Total' : { KEY_NODE_COUNT : 0, KEY_NODE_MEMORY : 0 } }

                caching_data.append( caching_results )

        return json_data

# ===========================================================================
# Copyright 2018 Autodesk, Inc. All rights reserved.
#
# Use of this software is subject to the terms of the Autodesk license
# agreement provided at the time of installation or download, or which
# otherwise accompanies this software in either electronic or hard copy form.
# ===========================================================================
