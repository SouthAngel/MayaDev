"""
Utility to verify that the evaluation manager is yielding the same results
as the Maya DG evaluation.

It is a simple wrapper around run_correctness_test().  See its documentation
for more details.

Legal values for modes are 'ems' and 'emp' with an optional '+XXX' to
indicate that evaluator XXX should be turned on during the test or an
optional '-XXX' to indicate that it should be turned off. Evaluator
states will be returned to their original value after the test is run.
If an evaluator is not explicitly listed the current state of it will
be used for the test.

e.g. modes=['ems','emp+deformer']  means run the comparison twice, first
against EM Serial mode, the second time against EM Parallel mode with
the 'deformer' evaluator turned on. You can use multiple evaluators if
you wish: modes=['ems+deformer-dynamics'].

Sample usage to run the tests on a single file:

    from maya.debug.emCorrectnessTest import emCorrectnessTest
    serialErrors = emCorrectnessTest(fileName='MyDir/MyFile.ma', resultsPath='MyDir/emCorrectness', modes=['ems'])[1]

Sample usage to run the tests on the current scene in parallel mode with the deformer evaluator and ignore output:

    from maya.debug.emCorrectnessTest import emCorrectnessTest
    parallelErrors = emCorrectnessTest(modes=['emp+deformer'])

Sample usage to run the tests on the current scene in serial and parallel mode and
show formatted detailed results in the script editor window:

    def comp1(a,b):
        print '    {}   {}'.format(a[0], b[0])
    def comp3(a,b):
        print '    {}'.format( '\n    '.join(str(numpy.array([a, b])).split('\n')) )
    def comp16(a,b):
        for i in range(4):
            print '    {}'.format( '\n    '.join(str(numpy.array([a[i*4:i*4+4], b[i*4:i*4+4]])).split('\n')) )

    from maya.debug.emCorrectnessTest import emCorrectnessTest
    import numpy
    results = emCorrectnessTest(verbose=True, modes=['ems','emp'], dataTypes=['mesh','number','matrix','screen'],maxFrames=300)
    print  '\nEM Correctness results'
    print  '=' * 22
    modeNames = {'ems':'EM Serial', 'emp':'EM Parallel'}
    for (result_type,result_list) in results.iteritems():
        if len(result_list) > 0:
            print '\nChanges in %s' % modeNames[result_type]
        for (plug,values) in result_list.iteritems():
            print '------' + plug
            try:
                array1 = [float(value) for value in values['value'].split(' ')]
                array2 = [float(value) for value in values['other'].split(' ')]
                if len(array1) == 1:
                    comp1(array1, array2)
                elif len(array1) == 3:
                    comp3(array1, array2)
                elif len(array1) == 16:
                    comp16(array1, array2)
            except ValueError:
                # If the comparison result isn't floats just print as-is
                print '    {}'.format( values['value'] )
                print '    {}'.format( values['other'] )

    # Put the summary at the end for easier reading
    for (resultType,result) in results.iteritems():
        print 'Change count for %s = %d' % (modeNames[resultType], len(result))
"""
import sys
import json
import maya.cmds as cmds
from maya.debug.correctnessUtils import run_correctness_test, multichain_nodes, CORRECTNESS_MAX_FRAMECOUNT, CORRECTNESS_NO_SETUP
from maya.debug.EvaluatorManager import EvaluatorManager
from maya.plugin.evaluator.CacheEvaluatorManager import CacheEvaluatorManager

__all__ = [ 'emCorrectnessTest' ]

#======================================================================

class EMCorrectnessContext(object):
    """
    This class shuts off the cache evaluator and the HIK evaluator in order to
    help minimize the sources of correctness errors.
    """
    def __init__(self):
        '''Create the evaluator managers and remember the desired configuration values'''
        # The caching must be disabled for correctness tests so that the points of
        # failure can be minimized. This test suite compares EM versus DG - the cache
        # correctness suite will compare EM versus cached EM.
        self.cache_mgr = CacheEvaluatorManager()

        # The HIK evaluator currently generates incorrect results in some situations
        # so until that is fixed it must be turned off for the correctness tests.
        self.hik_mgr = EvaluatorManager('hik','mayaHIK')

    #----------------------------------------------------------------------
    @staticmethod
    def should_pull_values():
        '''
        Ask if the values in this context are good as-is or if they have to be pulled to be valid
        :return: True if the evaluation manager is not active or it is in DG mode
        '''
        return cmds.evaluationManager(query=True, mode=True)[0] == 'off' or not cmds.evaluationManager(query=True, enabled=True)

    #----------------------------------------------------------------------
    def __enter__(self):
        '''Enter the section controlled by the context'''
        try:
            self.cache_mgr.__enter__()
        except Exception, ex:
            self.cache_mgr.__exit__(*sys.exc_info())
            raise ex
        try:
            self.hik_mgr.__enter__()
        except Exception, ex:
            self.hik_mgr.__exit__(*sys.exc_info())
            raise ex

        if self.cache_mgr.plugin_loaded:
            self.cache_mgr.enabled = False
        if self.hik_mgr.plugin_loaded:
            self.hik_mgr.enabled = False

        return self

    #----------------------------------------------------------------------
    def __exit__(self,exit_type,value,traceback):
        '''Exit the section controlled by the context, raising an exception if any restore failed'''
        exception = None

        try:
            self.cache_mgr.__exit__(exit_type, value, traceback)
        except Exception, ex:
            exception = ex

        try:
            self.hik_mgr.__exit__(exit_type, value, traceback)
        except Exception, ex:
            exception = ex

        if exception is not None:
            raise exception

#======================================================================

class EMCorrectnessMode(object):
    """
    This class represents a mode to be tested in EM correctness tests.
    """
    def __init__(self, mode):
        '''Remember the mode for these tests'''
        self.mode = mode

    def title(self):
        '''Get the title of this test mode'''
        return self.mode

    def em_mode(self):
        '''Get the name of the EM mode used for the tests'''
        return self.mode

    @staticmethod
    def context():
        '''Get the context in which the tests are to run'''
        return EMCorrectnessContext()

    def relevant_nodes(self, potential_nodes):
        '''
        :param potential_nodes: Set of nodes that could be evaluated/compared in the current mode
        :return: Subset of nodes relevant to the defined evaluation mode
        '''
        # The DG doesn't care how nodes are arranged, it accepts everything
        if self.mode == 'dg':
            return potential_nodes

        # For EM modes make sure the graph has been rebuilt
        with emModeManager() as em_mgr:
            em_mgr.rebuild()

        em_nodes = set()
        try:
            # EM modes check for visible animated nodes
            em_nodes = set( json.loads(cmds.dbpeek( op='graph', eg=True, a='nodes', all=True ))['nodes'] )
            with EvaluatorManager('invisibility',None) as inv_mgr:
                em_nodes = (em_nodes & potential_nodes) - set(inv_mgr.claimed_nodes( True ))

            # Multi-chain solver nodes do not play well with correctness tests
            em_nodes = em_nodes - multichain_nodes()

        except Exception:
            # With the EM unable to give answers no nodes can be safely compared
            em_nodes = set()

        return em_nodes

#======================================================================

def emCorrectnessTest( fileName=None
                     , resultsPath=None
                     , verbose=False
                     , modes=['ems']
                     , maxFrames=CORRECTNESS_MAX_FRAMECOUNT
                     , dataTypes=['matrix','vertex','screen']
                     , emSetup=CORRECTNESS_NO_SETUP ):
    """
    Evaluate the file in multiple evaluation manager modes and compare the results.

    fileName:    See fileName parameter in run_correctness_test.
    resultsPath: See resultsPath parameter in run_correctness_test.
    verbose:     See verbose parameter in run_correctness_test.
    modes:       List of modes to run the tests in. 'ems' and 'emp' are the
                 only valid ones. A mode can optionally enable or disable an
                 evaluator as follows:
                     'ems+deformer': Run in EM Serial mode with the deformer evalutor turned on
                     'emp-dynamics': Run in EM Parallel mode with the dynamics evalutor turned off
                     'ems+deformer-dynamics': Run in EM Serial mode with the dynamics evalutor
                                              turned off and the deformer evaluator turned on
    maxFrames:   See maxFrames parameter in run_correctness_test.
    dataTypes:   See dataTypes parameter in run_correctness_test.
    emSetup:     See emSetup parameter in run_correctness_test.

    Returns the output of run_correctness_test().
    """
    # No modes means no testing to run
    if modes is None:
        return []

    test_modes = [EMCorrectnessMode(mode) for mode in modes]

    return run_correctness_test( EMCorrectnessMode('dg')
                               , test_modes
                               , fileName
                               , resultsPath
                               , verbose
                               , maxFrames
                               , dataTypes
                               , emSetup
                               )

# ===========================================================================
# Copyright 2018 Autodesk, Inc. All rights reserved.
#
# Use of this software is subject to the terms of the Autodesk license
# agreement provided at the time of installation or download, or which
# otherwise accompanies this software in either electronic or hard copy form.
# ===========================================================================
