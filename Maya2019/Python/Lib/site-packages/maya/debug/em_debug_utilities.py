import maya
maya.utils.loadStringResourcesForModule(__name__)

'''
Collection of utilities to support debug output for various views into the evaluation manager data
'''

__all__ = [ 'dbg_nodes'
          , 'dbg_graph'
          , 'dbg_scheduling_graph'
          , 'dbg_scheduling_types'
          , 'convert_exception_to_unicode'
          , 'dbg_graph_to_dot'
          , 'dbg_scheduling_graph_to_dot'
          , 'get_default_directory'
          , 'get_minimal_scene_objects_from'
          , 'open_file'
          , 'require_evaluation_graph'
          ]

import os
import sys
import json
import locale
import subprocess
import tempfile
import maya.cmds as cmds
from functools import wraps
from maya.debug.emModeManager import emModeManager

DOWNSTREAM_LINK = '[]-->'
UPSTREAM_LINK = '-->[]'
PLUG_TYPES = { 'input' : UPSTREAM_LINK, 'output' : DOWNSTREAM_LINK, 'affectsWorld' : '[-W>]', 'attributes' : '[---]' }

# Message to give when generation of the EG or SG information fails due to the graph not yet existing
GRAPH_NOT_AVAILABLE = maya.stringTable['y_em_debug_utilities.kEGNotAvailable' ]

#======================================================================
def convert_exception_to_unicode(exception):
    """
    :return: a string representing the exception, in Unicode format.

    It handles cases such as when WindowsError exceptions contain Unicode
    characters encoded in a regular string in the OS encoding.  It does
    so in a slightly more generic and robust way by also trying the
    system's locale encoding.
    """
    message = str(exception)
    encodings_to_try = [
        [],
        [sys.getdefaultencoding()],
        [locale.getpreferredencoding()],
        ]
    for encoding in encodings_to_try:
        try:
            return message.decode(*encoding)
        except UnicodeDecodeError:
            pass

    # Nothing worked, resort to repr()
    return unicode(repr(message))

#======================================================================
def collapse_lists(list_of_items):
    '''
    Convert a list of mixed strings and other iterables to a list of unique items
    :param list_of_items: List consisting of strings, tuples, or other lists to be collapsed
    :return: List consisting of unique strings that were somewhere in the input list structure
    '''
    result_list = []
    for item in list_of_items or []:
        if not isinstance(item,(tuple,list,set)):
            result_list.append( str(item) )
        else:
            result_list += [sub_item for sub_item in item]
    # Make it a unique list before returning
    return list(set(result_list))

#======================================================================
def dbpeek_selection_expansion(expansion_type, use_selection, selection_depth, peek_args):
    '''
    Take the current configuration and figure out the parameters required by the dbpeek
    command to handle the selection.
    The two selection settings are the All/Selected boolean, and the integer depth. When
    "All" is selected every node is used, otherwise the selection is expanded "depth" steps and
    the expanded selection list is returned (without actually changing the selection).

    :param expansion_type: Type of graph for selection expansion, if needed (DG, SG, or DG)
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :param peek_args: Initial arguments in use by the dbpeek command, modified to include
                         any extra arguments required to respect the current selection settings

    :return: List of the expanded selection, empty list if using all nodes
    '''
    selection = []
    if not use_selection:
        peek_args['all'] = True
    else:
        # The expansion happens even when the depth is 0 because it will expand within a
        # cluster to include all nodes in the same cluster.
        selected = cmds.ls(sl=True)
        if len(selected or []) > 0:
            selection = collapse_lists( cmds.expandedSelection( cmds.ls(sl=True), expansionType=expansion_type, depth=selection_depth ) )
            if len(selection) == 0:
                raise RuntimeError( maya.stringTable['y_em_debug_utilities.kIrrelevantSelection'] )
        else:
            raise RuntimeError( maya.stringTable['y_em_debug_utilities.kEmptySelection'] )

    return selection

#======================================================================
def dbg_nodes(summary_only, include_plugs, use_selection, selection_depth):
    '''
    Generate a string representing the evaluation graph nodes.
    :param summary_only: If True then just summarize the information rather than using JSON format
    :param include_plugs: If True then include the lists of dirty plugs the evaluation node knows about
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :return: Evaluation node structure in string form, None if the graph was not available
    '''

    # if the graph is not valid then don't try to display it
    if not cmds.evaluationManager( query=True, invalidate=True ):
        raise RuntimeError( GRAPH_NOT_AVAILABLE )

    peek_args = { 'op' : 'graph', 'evaluationGraph' : True, 'argument' : ['nodes'] }
    if include_plugs:
        peek_args['argument'].append( 'plugs' )
    selection = dbpeek_selection_expansion( 'EG', use_selection, selection_depth, peek_args )
    results = cmds.dbpeek( selection, **peek_args )

    if summary_only:
        node_data = json.loads( results )
        results = ''
        if include_plugs:
            plug_list = node_data['plugs']
            node_list = plug_list.keys()
            for node in sorted(node_list):
                results += '{}\n'.format( node )
                for plug_type,plug_decoration in PLUG_TYPES.iteritems():
                    for plug in sorted(plug_list[node][plug_type]):
                        results += '    {} {}\n'.format( plug_decoration, plug )
        else:
            for node in sorted(node_data['nodes']):
                results += '{}\n'.format(node)

    return results

#======================================================================
def dbg_graph(summary_only, include_plugs, use_selection, selection_depth):
    '''
    Generate a string representing the evaluation graph nodes and connections.
    :param summary_only: If True then just summarize the information rather than using JSON format
    :param include_plugs: If True then include the lists of dirty plugs the evaluation node knows about
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :return: Evaluation graph structure in string form
    :raise RuntimeError: if the graph was not available
    '''

    # if the graph is not valid then don't try to display it
    if not cmds.evaluationManager( query=True, invalidate=True ):
        raise RuntimeError( GRAPH_NOT_AVAILABLE )

    peek_args = { 'op' : 'graph', 'evaluationGraph' : True, 'argument' : ['connections'] }
    if include_plugs:
        peek_args['argument'].append( 'plugs' )
    selection = dbpeek_selection_expansion( 'EG', use_selection, selection_depth, peek_args )
    results = cmds.dbpeek( selection, **peek_args )

    if summary_only:
        try:
            json_results = json.loads( results )
            graph_data = json_results['connections']
        except ValueError:
            raise RuntimeError( maya.stringTable['y_em_debug_utilities.kNoConnectionData' ] )
        results = ''
        plugs = {}
        if include_plugs and (len(graph_data) > 0):
            try:
                plugs = json_results['plugs']
            except ValueError:
                raise RuntimeError( maya.stringTable['y_em_debug_utilities.kNoPlugData' ] )
        for node in sorted(graph_data.keys()):
            node_connections = graph_data[node]
            results += '{}\n'.format( node )
            #--------------------
            downstream_list = []
            for downstream in node_connections['downstream']:
                downstream_list += downstream.values()
            for downstream_node in downstream_list:
                results += '    --> {}\n'.format(downstream_node)
            #--------------------
            upstream_list = []
            for upstream in node_connections['upstream']:
                upstream_list += upstream.keys()
            for upstream_node in upstream_list:
                results += '    <-- {}\n'.format(upstream_node)
            #--------------------
            if node in plugs:
                results += '    Plugs\n'
                for plug_type,plug_decoration in PLUG_TYPES.iteritems():
                    for plug in sorted(plugs[node][plug_type]):
                        results += '        {} {}\n'.format( plug_decoration, plug )

    return results

#======================================================================
def dbg_scheduling_graph(summary_only, include_clusters, use_selection, selection_depth):
    '''
    Generate a string representing the scheduling graph structure
    :param summary_only: If True then just summarize the information rather than using JSON format
    :param include_clusters: If True then include the members of each cluster rather than just a membership size
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :return: Scheduling graph structure in string form
    :raise RuntimeError: if the graph was not available
    '''

    peek_args = { 'op' : 'graph', 'evaluationGraph' : True, 'argument' : ['scheduling'] }
    selection = dbpeek_selection_expansion( 'SG', use_selection, selection_depth, peek_args )
    scheduling_data = cmds.dbpeek( selection, **peek_args )

    try:
        # Since accessing dictionary values doesn't create copies setting up these temporary
        # variables is cheap, and serves to validate the input
        scheduling_json = json.loads(scheduling_data)['scheduling']
        edges = scheduling_json['Edges']
        evaluation = scheduling_json['Evaluation']
        clusters = scheduling_json['Clusters']
    except Exception:
        raise RuntimeError( GRAPH_NOT_AVAILABLE )

    if summary_only:
        # Only downstream connections are in the data. Create the reverse connection
        # list as well before dumping.
        upstream_nodes = {}
        for node,downstream_nodes in edges.iteritems():
            for downstream_node in downstream_nodes:
                upstream_nodes[downstream_node] = upstream_nodes.get( downstream_node, [] ) + [node]

        # Dump in a format similar to the evaluation graph, with each node appearing
        # alphabetically, along with its input and output connections. In the case of the
        # scheduling graph a "node" could be a cluster. When the include_clusters flag is
        # set those will include the cluster members, similar to how dirty plugs are included in
        # the evaluation graph dump.
        results = ''
        for node,downstream_nodes in edges.iteritems():
            results += '{}\n'.format(node)
            for downstream_node in downstream_nodes:
                results += '    {} {}\n'.format(DOWNSTREAM_LINK, downstream_node)
            if node in upstream_nodes:
                for upstream_node in upstream_nodes[node]:
                    results += '    {} {}\n'.format(UPSTREAM_LINK, upstream_node)
            if include_clusters:
                # For some reason the cluster is named differently in the cluster list
                cluster_name = node.replace( "Cluster_", "", 1 )
                if cluster_name in clusters:
                    results += '    Cluster Contains: [\n'
                    for cluster_node in clusters[cluster_name]:
                        results += '      {}\n'.format( cluster_node )
                    results += '    ]\n'
    else:
        raw_json = { 'scheduling' : { 'Evaluation' : evaluation } }
        if include_clusters:
            raw_json['scheduling']['Clusters'] = clusters
        results = json.dumps( raw_json, indent=4 )

    return results

#======================================================================
def dbg_scheduling_types(summary_only, use_selection, selection_depth):
    '''
    Generate a string representing the scheduling types of nodes
    :param summary_only: If True then just summarize the information rather than using JSON format
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :return: String containing the scheduling type information
    :raise RuntimeError: if the graph was not available
    '''

    # These types match the JSON keys provided by the dbpeek command
    scheduling_types = ['Parallel', 'Serial', 'GloballySerial', 'Untrusted']

    peek_args = { 'op' : 'graph', 'evaluationGraph' : True, 'argument' : ['scheduling'] }
    selection = dbpeek_selection_expansion( 'SG', use_selection, selection_depth, peek_args )
    scheduling_data = cmds.dbpeek( selection, **peek_args )

    try:
        scheduling_info = {k:v for k,v in json.loads( scheduling_data )['scheduling'].iteritems() if k in scheduling_types }
    except ValueError:
        raise RuntimeError( GRAPH_NOT_AVAILABLE )

    if summary_only:
        results = ''
        for scheduling_type,scheduling_list in scheduling_info.iteritems():
            if len(scheduling_list) > 0:
                results += '{}\n'.format( scheduling_type )
                for node in sorted(scheduling_list):
                    results += '    {}\n'.format( node )
    else:
        results = json.dumps( { 'scheduling' : scheduling_info }, indent=4 )

    return results

#======================================================================
def dbg_graph_to_dot(include_plugs, use_selection, selection_depth, out_dot):
    '''
    Generate a string representing the evaluation graph nodes and connections in a DOT visualization format.
    :param include_plugs: If True then include the lists of dirty plugs the evaluation node knows about
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :param out_dot: File where the .dot format data should go
    :return: Full path to the .dot file location
    :raise RuntimeError: if the graph was not available
    '''

    # if the graph is not valid then don't try to display it
    if not cmds.evaluationManager( query=True, invalidate=True ):
        raise RuntimeError( GRAPH_NOT_AVAILABLE )

    peek_args = { 'op' : 'graph', 'evaluationGraph' : True, 'argument' : ['connections', 'dot'] }
    peek_args['outputFile'] = out_dot
    if include_plugs:
        peek_args['argument'] += ['verbose']
    selection = dbpeek_selection_expansion( 'EG', use_selection, selection_depth, peek_args )

    try:
        cmds.dbpeek( selection, **peek_args )
    except Exception, ex:
        raise RuntimeError( str(ex) )

    return out_dot

#======================================================================
def dbg_scheduling_graph_to_dot(include_clusters, use_selection, selection_depth, out_dot):
    '''
    Generate a string representing the evaluation graph nodes and connections in a DOT visualization format.
    :param include_clusters: If True then include the members of each cluster rather than just a membership size
    :param use_selection: True if the selection list should be used, otherwise use all nodes
    :param selection_depth: Number of steps from selected nodes to include, if selection is being used
    :param out_dot: File where the .dot format data should go
    :return: Full path to the .dot file location
    :raise RuntimeError: if the graph was not available
    '''

    # if the graph is not valid then don't try to display it
    if not cmds.evaluationManager( query=True, invalidate=True ):
        raise RuntimeError( GRAPH_NOT_AVAILABLE )

    peek_args = { 'op' : 'graph', 'evaluationGraph' : True, 'argument' : ['scheduling', 'dot'] }
    peek_args['outputFile'] = out_dot
    if include_clusters:
        peek_args['argument'] += ['verbose']
    selection = dbpeek_selection_expansion( 'SG', use_selection, selection_depth, peek_args )

    try:
        cmds.dbpeek( selection, **peek_args )
    except Exception, ex:
        raise RuntimeError( str(ex) )

    return out_dot

#======================================================================
def require_evaluation_graph(func):
    """
    This decorator makes sure that the given function will have a valid
    evaluation graph.
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        '''Define a wrapper to validate the evaluation graph before running the function'''
        # Make sure evaluation manager is active.
        mode_mgr = emModeManager()
        if 'off' == mode_mgr.mode:
            cmds.error( maya.stringTable['y_em_debug_utilities.kEvaluationManagerNotActive' ] )
            return

        if mode_mgr.invalid:
            # The graph is not ready.
            mode_mgr.invalid = True

            # Sometimes anim curves may decide to invalidate the graph so do it again.
            if mode_mgr.invalid:
                mode_mgr.invalid = True

        # We should have a valid evaluation graph.  If that is not the case,
        # we let the function go through anyways and let it catch the error.
        return func(*args, **kwargs)

    return wrapper

#======================================================================
def open_file(file_name):
    """
    Open up an output file with the application assigned to it by the OS.

    :param file_name: File to be opened up (usually a PDF or DOT file but can be any recognized format)
    """
    try:
        if sys.platform == 'win32':
            os.startfile(file_name)
        else:
            opener = 'open' if sys.platform == 'darwin' else 'xdg-open'
            subprocess.call([opener, file_name])
    except Exception as ex:
        message = maya.stringTable['y_em_debug_utilities.kErrorFileOpen' ]
        cmds.error( message.format(file_name, convert_exception_to_unicode(ex)))
        return

#======================================================================
def get_default_directory():
    '''Get a reasonable default directory for temporary output.'''
    default_path = os.getenv('MAYA_DEBUG_DIRECTORY')
    if default_path is None:
        default_path = tempfile.gettempdir()
    return os.path.normpath( default_path )

#======================================================================
# The following methods are used to get the minimal dependencies.
# Only get_minimal_scene_objects_from() is exposed
def get_upstream_set(starting_nodes):
    '''
    Find all nodes one step upstream from the starting_nodes
    :param starting_nodes: Initial nodes from which to go upstream
    :return: Unique list of the starting_nodes plus any nodes one step upstream from them
    '''
    cmds.select(clear=True)

    upstream_set = set(starting_nodes)
    nodes_to_process = []
    nodes_to_process.extend(starting_nodes)

    while len(nodes_to_process) > 0:
        node = nodes_to_process.pop()
        parentList = cmds.evaluationManager(upstreamFrom=node) or []
        cycleList = cmds.evaluationManager(cycleCluster=node) or []
        for oneParent in parentList:
            if oneParent not in upstream_set:
                upstream_set.add(oneParent)
                nodes_to_process.append(oneParent)
        for oneParent in cycleList:
            if oneParent not in upstream_set:
                upstream_set.add(oneParent)
                nodes_to_process.append(oneParent)

    return list(upstream_set)

#======================================================================
def expand_to_upstream_hierarchy(input_list):
    '''
    Traverse upstream through the evaluation graph to find nodes related
    to those in the starting_nodes list.
    :param starting_nodes: Initial nodes from which to go upstream
    :return: Unique list of all nodes upstream from and including the starting_nodes
    '''
    return_set = set()

    nodes_to_process = []
    nodes_to_process.extend(input_list)

    while len(nodes_to_process) > 0:
        node = nodes_to_process.pop()
        return_set.add(node)

        parentList = cmds.listRelatives(node, fullPath=True, parent=True) or []
        for parentNode in parentList:
            if parentNode not in return_set:
                nodes_to_process.append(parentNode)

    return list(return_set)

#======================================================================
def expand_to_shapes(input_list):
    '''
    Expand an input_list to include all shapes below them in the DAG
    :param input_list: List of nodes for which shapes are to be added
    :return: Input list plus any shapes below transforms that appear in the input_list
    '''
    shapes = set()
    for node in input_list:
        nodeType = cmds.nodeType(node)

        if nodeType == 'transform':
            shape_list = cmds.listRelatives(node, fullPath=True, shapes=True) or []
            for shape_node in shape_list:
                shapes.add(shape_node)
    expanded_list = list(shapes) + input_list
    return expanded_list

#======================================================================
def get_minimal_scene_objects_from(input_list):
    '''
    :param input_list: List of nodes that are required in the minimal scene
    :return: List of nodes required in order to correctly evaluate the nodes in input_list
    '''
    upstream = get_upstream_set(input_list)
    upstream_with_dag = expand_to_upstream_hierarchy(upstream)
    upstream_with_dag_and_shapes = expand_to_shapes(upstream_with_dag)
    return upstream_with_dag_and_shapes

#======================================================================
def select_inverse_visible_dag_objects(original_nodes):
    '''Create an inverse selection list from the specified original nodes'''

    if len(original_nodes) == 0:
        # Nothing was selected, so there is nothing to do...
        return

    cmds.select(original_nodes)

    # Determine if we have any visible selected dag objects, otherwise
    # there is nothing to do
    objects = cmds.ls(dagObjects=True, visible=True, selection=True)

    if len(objects) != 0:
        # Inverse: Remove all visible dagObjects in our original list from
        # the selection and add all the invisible ones
        cmds.select(toggle=True, allDagObjects=True, visible=True)

        # Deselect the parents and select any unneeded siblings
        parents = cmds.listRelatives(original_nodes, parent=True, path=True)
        if parents:
            if len(parents) > 0:
                # Remove all parents from in our original list from the selection
                cmds.select(parents, deselect=True)
                children = cmds.listRelatives(parents, children=True, path=True)
                cmds.select(children, add=True)

        # make sure the original objects in the original list are not selected
        cmds.select(original_nodes, deselect=True)
# ===========================================================================
# Copyright 2018 Autodesk, Inc. All rights reserved.
#
# Use of this software is subject to the terms of the Autodesk license
# agreement provided at the time of installation or download, or which
# otherwise accompanies this software in either electronic or hard copy form.
# ===========================================================================
